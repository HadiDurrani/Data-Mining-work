{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MckRZ-0b2GY",
        "outputId": "56e561d9-ca5f-489d-94cf-43ab1a794392"
      },
      "outputs": [],
      "source": [
        "!pip install apyori"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekp7Ecfcb_Ev"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from apyori import apriori"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81SW3RowcF2L"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('DATA.csv', nrows = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "99w-1xL6hrMt",
        "outputId": "c0d80c8a-b620-4737-a4e6-75785f99d781"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0TAp4uvj1lx"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['39','77516','13','2174','0','40'],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5kJov3zHkFSv",
        "outputId": "80373d38-b3d4-4d1c-fb1b-fa09363df4a0"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvFMPF7ycOiI"
      },
      "outputs": [],
      "source": [
        "records = []\n",
        "for i in range(0, 100):\n",
        "    records.append([str(df.values[i,u]) for u in range(0, 9)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFT2eE4CcSsy"
      },
      "outputs": [],
      "source": [
        "rules = apriori(records, min_support=0.0022, min_confidence=0.20, min_lift=3, min_length = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mcnghZGcYek"
      },
      "outputs": [],
      "source": [
        "# Store rules in result variable\n",
        "results = list(rules)# See the items that were bought together with their support\n",
        "results_list = []\n",
        "for i in range(0, len(results)):\n",
        "    results_list.append('RULE:\\t' + str(results[i][0]) + '\\nSUPPORT:\\t' + str(results[i][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi8z_sTFcZ0T"
      },
      "outputs": [],
      "source": [
        "print(len(results_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm40j3p7ceJM"
      },
      "outputs": [],
      "source": [
        "print(results_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe-NzpXFm7tR"
      },
      "source": [
        "RULE 1:\\tfro\n",
        "zenset({'Instant food products', 'hamburger meat'})\\nSUPPORT:\\t0.003050330452465684\n",
        "\n",
        "If a customer buys \"Instant food products\" and \"hamburger meat\", then there is a support of 0.00305, which means that these items are purchased together in approximately 0.305% of all transactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9173UnHYbY_H"
      },
      "outputs": [],
      "source": [
        "columns=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
        "df = pd.read_csv('DATA.csv',header=None,names=columns)\n",
        "df.head()\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "df.columns\n",
        "\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64', 'int32']).columns\n",
        "num_cols\n",
        "\n",
        "# One-Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "# Create a new DataFrame with only relevant columns\n",
        "categorical_df = df[categorical_cols]\n",
        "num_df=df[num_cols]\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "# Fit and transform the categorical data\n",
        "encoded_data = encoder.fit_transform(categorical_df).toarray()\n",
        "\n",
        "# Create a DataFrame from the encoded data\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "# Combine the encoded DataFrame with the original numeric columns\n",
        "binarized_df = pd.concat([encoded_df], axis=1)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(binarized_df.head())\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Set your support and confidence thresholds\n",
        "min_support_values = [0.05, 0.1, 0.15]\n",
        "min_confidence = 0.7\n",
        "\n",
        "# Calculate frequent itemsets\n",
        "for min_support in min_support_values:\n",
        "    frequent_itemsets = apriori(binarized_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "    # Extract association rules\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "    # Rank the top 10 rules\n",
        "    top_10_rules = rules.nlargest(10, \"confidence\")\n",
        "\n",
        "    # Print rules and explanations\n",
        "    print(f\"Rules for min_support={min_support:.2f}:\")\n",
        "    for i, (_, row) in enumerate(top_10_rules.iterrows(), start=1):\n",
        "        antecedent = row['antecedents']\n",
        "        consequent = row['consequents']\n",
        "        confidence = row['confidence']\n",
        "\n",
        "        print(f\"Rule {i}: If {antecedent} then {consequent} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "def calculate_interest(rule):\n",
        "    return rule['confidence'] * rule['lift']\n",
        "\n",
        "min_support_values = [0.05, 0.1, 0.15]\n",
        "min_interest_values = [0.5, 0.7, 0.9]\n",
        "\n",
        "for min_support in min_support_values:\n",
        "    frequent_itemsets = apriori(binarized_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "    for min_interest in min_interest_values:\n",
        "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "        # Calculate interest measure for each rule\n",
        "        rules['interest'] = rules.apply(calculate_interest, axis=1)\n",
        "\n",
        "        # Rank the top 10 rules based on interest\n",
        "        top_10_rules = rules.nlargest(10, \"interest\")\n",
        "\n",
        "        # Print rules and explanations\n",
        "        print(f\"Rules for min_support={min_support:.2f} and min_interest={min_interest:.2f}:\")\n",
        "        for i, (_, row) in enumerate(top_10_rules.iterrows(), start=1):\n",
        "            antecedent = row['antecedents']\n",
        "            consequent = row['consequents']\n",
        "            confidence = row['confidence']\n",
        "            lift = row['lift']\n",
        "            interest = row['interest']\n",
        "\n",
        "            print(f\"Rule {i}: If {antecedent} then {consequent} (Confidence: {confidence:.2f}, Lift: {lift:.2f}, Interest: {interest:.2f})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
